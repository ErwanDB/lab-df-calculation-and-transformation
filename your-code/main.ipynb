{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "You work in the data analysis team of a very important company. On Monday, the company shares some good news with you: you just got hired by a major retail company! So, let's get prepared for a huge amount of work!\n",
    "\n",
    "Then you get to work with your team and define the following tasks to perform:   \n",
    "1. You need to start your analysis using data from the past.  \n",
    "2. You need to define a process that takes your daily data as an input and integrates it.  \n",
    "\n",
    "You are in charge of the second part, so you are provided with a sample file that you will have to read daily. To complete you task, you need the following aggregates:\n",
    "* One aggregate per store that adds up the rest of the values.\n",
    "* One aggregate per item that adds up the rest of the values.\n",
    "\n",
    "You can import the `raw_sales` table from the database `retail_sales` fon of Ironhack's databases. \n",
    "\n",
    "## Your task\n",
    "Therefore, your process will consist of the following steps:\n",
    "1. Read the sample file that a daily process will save in your folder. \n",
    "2. Clean up the data.\n",
    "3. Create the aggregates.\n",
    "4. Write three tables in your local database: \n",
    "    - A table for the cleaned data.\n",
    "    - A table for the aggregate per store.\n",
    "    - A table for the aggregate per item.\n",
    "\n",
    "## Instructions\n",
    "* Clean the data and create the aggregates as you consider.\n",
    "* Create the tables in your local database.\n",
    "* Populate them with your process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Datasets_as_CSV/retail_sales-raw_sales.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the path of the file: ../Datasets_as_CSV/retail_sales-raw_sales.csv\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Inputs user\n",
    "path = input('Enter the path of the file: ',)\n",
    "\n",
    "# Data aquisition\n",
    "def acquire(path):\n",
    "    data = pd.read_csv(path, sep=\";\",index_col = 'date',parse_dates=True)\n",
    "    return data\n",
    "\n",
    "# Data Wrangle\n",
    "def wrangle(df):\n",
    "    df['total_amount'] = df['item_price']*df['item_cnt_day']\n",
    "    return df\n",
    "    \n",
    "# Data Analysis\n",
    "def analyze_by_items(df):\n",
    "    item = pd.DataFrame(df.groupby(['item_id','item_price'])[['item_cnt_day','total_amount']].sum())\n",
    "    return item\n",
    "\n",
    "def analyze_by_shop(df):\n",
    "    shop = df.groupby('shop_id').agg({'total_amount':'sum'})\n",
    "    return shop\n",
    "\n",
    "# Export data\n",
    "def export_tables(item,shop):\n",
    "    with pd.ExcelWriter('sales.xlsx') as writer:\n",
    "        item.to_excel(writer, sheet_name='items')\n",
    "        shop.to_excel(writer, sheet_name='shop')\n",
    "    \n",
    "# Execution\n",
    "if __name__ == '__main__':\n",
    "    data = acquire(path)\n",
    "    df = wrangle(data)\n",
    "    item = analyze_by_items(df)\n",
    "    shop = analyze_by_shop(df)\n",
    "    export_tables(item,shop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
